{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, TimeDistributed,Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length:  600893\n"
     ]
    }
   ],
   "source": [
    "path= get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text= io.open(path, encoding='utf-8').read().lower()\n",
    "print ('corpus length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  57\n"
     ]
    }
   ],
   "source": [
    "chars= sorted(list(set(text)))\n",
    "print ('total chars: ', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ä', 'æ', 'é', 'ë']\n"
     ]
    }
   ],
   "source": [
    "print (chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices= dict((c,i) for i,c in enumerate(chars))\n",
    "indices_char= dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences:  200285\n"
     ]
    }
   ],
   "source": [
    "max_len=40\n",
    "step=3\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "for i in range(0,len(text)-max_len, step):\n",
    "    sentences.append(text[i:i+max_len])\n",
    "    next_chars.append(text[i+max_len])\n",
    "print ('nb sequences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization....\n",
      "(200285, 40, 57) (200285, 57)\n"
     ]
    }
   ],
   "source": [
    "print ('Vectorization....')\n",
    "x=np.zeros((len(sentences), max_len, len(chars)), dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
    "print (x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,sentence in enumerate(sentences):\n",
    "    for t,char in  enumerate(sentence):\n",
    "        x[i,t,char_indices[char]]=1\n",
    "    y[i,char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 57)                7353      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 57)                0         \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(512, input_shape=(max_len,len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "# optimizer= RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds,temperature=1):\n",
    "    preds=np.asarray(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "#     print (preds)\n",
    "    exp_preds=np.exp(preds)\n",
    "#     print (exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "#     print (probas)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 99s 495us/step - loss: 2.1316\n",
      "Generated with seed: \"e have poor talents for it. one\n",
      "may make\"\n",
      "e have poor talents for it. one\n",
      "may make~ ~t~h~e~ ~s~o~m~e~ "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:403: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e~ ~s~o~m~e~ ~t~h~e\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.5f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "model.fit(x,y, batch_size=128, epochs=1, callbacks=[checkpoint])\n",
    "start_index= random.randint(0,len(text)-max_len-1)\n",
    "\n",
    "generated=''\n",
    "sentence=text[start_index:start_index+max_len]\n",
    "generated+=sentence\n",
    "print ('Generated with seed: \"'+sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(400):\n",
    "    x_pred= np.zeros((1,max_len,len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0,t,char_indices[char]]=1.\n",
    "\n",
    "    preds=model.predict(x_pred, verbose=0)[0]\n",
    "    next_index= np.argmax(preds)\n",
    "    next_char=indices_char[next_index]\n",
    "\n",
    "    generated+=next_char\n",
    "    sentence=sentence[1:]+next_char\n",
    "    sys.stdout.write(\"~\")\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.5f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "model.fit(x,y, batch_size=128, epochs=1, callbacks=[checkpoint])\n",
    "start_index= random.randint(0,len(text)-max_len-1)\n",
    "\n",
    "for diversity in [0.2,0.5,1.0,1.2]:\n",
    "    print('Diversity: ',diversity)\n",
    "    generated=''\n",
    "    sentence=text[start_index:start_index+max_len]\n",
    "    generated+=sentence\n",
    "    print ('Generated with seed: \"'+sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred= np.zeros((1,max_len,len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0,t,char_indices[char]]=1.\n",
    "\n",
    "        preds=model.predict(x_pred, verbose=0)[0]\n",
    "        next_index= sample(preds, diversity)\n",
    "        next_char=indices_char[next_index]\n",
    "\n",
    "        generated+=next_char\n",
    "        sentence=sentence[1:]+next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,50):\n",
    "    print('-'*50)\n",
    "    print ('iteration: ',i)\n",
    "    checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.5f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    model.fit(x,y, batch_size=128, epochs=1,callbacks=[checkpoint])\n",
    "    start_index= random.randint(0,len(text)-max_len-1)\n",
    "    \n",
    "    for diversity in [0.2,0.5,1.0,1.2]:\n",
    "        print('Diversity: ',diversity)\n",
    "        generated=''\n",
    "        sentence=text[start_index:start_index+max_len]\n",
    "        generated+=sentence\n",
    "        print ('Generated with seed: \"'+sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        \n",
    "        for i in range(400):\n",
    "            x_pred= np.zeros((1,max_len,len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0,t,char_indices[char]]=1.\n",
    "            \n",
    "            preds=model.predict(x_pred, verbose=0)[0]\n",
    "            next_index= sample(preds, diversity)\n",
    "            next_char=indices_char[next_index]\n",
    "            \n",
    "            generated+=next_char\n",
    "            sentence=sentence[1:]+next_char\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
